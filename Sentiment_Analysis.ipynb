{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq7koqdRv_ul"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Uy5XVe81IVP"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7NK8kg-tpi1"
      },
      "source": [
        "# Load in the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download reviews.txt\n",
        "!wget https://raw.githubusercontent.com/GargPriyanshu1112/Sentiment-Analysis/main/reviews.txt\n",
        "\n",
        "# Download labels.txt\n",
        "!wget https://raw.githubusercontent.com/GargPriyanshu1112/Sentiment-Analysis/main/labels.txt"
      ],
      "metadata": {
        "id": "lPJH1e8ccdta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bad7d91-b5fb-4fe9-d3de-fb052f5ef695"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-09 05:39:58--  https://raw.githubusercontent.com/GargPriyanshu1112/Sentiment-Analysis/main/reviews.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33678267 (32M) [text/plain]\n",
            "Saving to: ‘reviews.txt’\n",
            "\n",
            "reviews.txt         100%[===================>]  32.12M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-08-09 05:40:02 (354 MB/s) - ‘reviews.txt’ saved [33678267/33678267]\n",
            "\n",
            "--2022-08-09 05:40:02--  https://raw.githubusercontent.com/GargPriyanshu1112/Sentiment-Analysis/main/labels.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225000 (220K) [text/plain]\n",
            "Saving to: ‘labels.txt’\n",
            "\n",
            "labels.txt          100%[===================>] 219.73K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2022-08-09 05:40:02 (63.3 MB/s) - ‘labels.txt’ saved [225000/225000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V8pfPkdzwaUY"
      },
      "outputs": [],
      "source": [
        "# Read data from text files\n",
        "with open(\"reviews.txt\") as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "with open(\"labels.txt\") as f:\n",
        "  labels = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0_891cswaR1"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "3hDswTlHwaN2",
        "outputId": "4624a31b-f3e6-4303-822c-f0506621171c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\nstory of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "reviews[: 1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nftXoEDa1PiV",
        "outputId": "b00ccf6b-2a46-4674-a1a8-e5f20b481109"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n',\n",
              " ' ',\n",
              " '.',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Characters present in reviews \n",
        "set(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "yCAzcUAW7yiH",
        "outputId": "240fb502-212f-4fcd-fee2-c03924b88e4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'positive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nn'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "labels[: 1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">We need to eliminate `'\\n'` character and other punctuations."
      ],
      "metadata": {
        "id": "ZIWhQX3zf40S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-PY6P12wh8q"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "av2vrKZ2FBYs",
        "outputId": "70989da3-fdb7-4e56-af1f-8084b34814d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t    story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Convert alphabets to lowercase\n",
        "text = reviews.lower()\n",
        "\n",
        "# Remove the punctuations\n",
        "text = ''.join([char  for char in text  if char not in punctuation])\n",
        "\n",
        "# Remove '\\n' character\n",
        "reviews_split = text.split('\\n') # List of reviews\n",
        "text = ' '.join(reviews_split)\n",
        "\n",
        "text[: 1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xar34Or4cV1e",
        "outputId": "b849b4fc-63d3-4c09-be6f-09482a5a1f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Separate the labels\n",
        "labels = labels.split()\n",
        "\n",
        "labels[: 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVmO14LWVMbO",
        "outputId": "a73deafe-4c57-4c57-d611-d7a69aa647bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-length reviews: 1\n"
          ]
        }
      ],
      "source": [
        "# Check if zero-length reviews are present\n",
        "review_lengths = Counter(len(review.split())  for review in reviews_split)\n",
        "print(f\"Zero-length reviews: {review_lengths[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "21XIlRHtWzZp"
      },
      "outputs": [],
      "source": [
        "# Get index of reviews having non-zero length\n",
        "non_zero_idxs = [idx  for idx, review in enumerate(reviews_split)  if len(review)!=0]\n",
        "\n",
        "# Remove zero-length reviews and their corresponding labels\n",
        "reviews_split = [reviews_split[idx]  for idx in non_zero_idxs]\n",
        "labels = [labels[idx]  for idx in non_zero_idxs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqp1qZse6R3E",
        "outputId": "8e70cb81-21c1-40e2-cdfb-0dfb29b65049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of reviews: 25000\n",
            "No. of labels : 25000\n"
          ]
        }
      ],
      "source": [
        "print(f\"No. of reviews: {len(reviews_split)}\")\n",
        "print(f\"No. of labels : {len(labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Vocabulary"
      ],
      "metadata": {
        "id": "mjgSAvF_h3aH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As78k33QAB4_",
        "outputId": "e815a436-54c4-4c5c-e2d5-074d22e787f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are a total of 6020196 words in reviews.\n",
            "\n",
            "Some of the are:\n",
            "   ['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other']\n"
          ]
        }
      ],
      "source": [
        "# Get a list of words used in reviews\n",
        "words = text.split()\n",
        "print(f\"\\nThere are a total of {len(words)} words in reviews.\")\n",
        "print()\n",
        "print(f\"Some of the are:\\n   {words[: 15]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO_YoFSYKmsV",
        "outputId": "bfb8095a-bdf2-4b6d-a5f4-7fad0c2ca078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 74072 words in the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# Get vocabulary\n",
        "vocabulary = set(words)\n",
        "\n",
        "# Get vocabulary size\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "print(f\"There are {vocab_size} words in the vocabulary.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNNTIyOmeWGn"
      },
      "source": [
        "# Encoding the Words\n",
        "\n",
        "\n",
        ">We pass in integers to our network. Therefore, we need to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_tiHRzXyWlI",
        "outputId": "369bcf15-66cb-44c3-e1bf-74067ed57b02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'animators': 6,\n",
              " 'catchword': 2,\n",
              " 'hermandad': 9,\n",
              " 'meter': 10,\n",
              " 'passive': 7,\n",
              " 'perseus': 4,\n",
              " 'slitting': 8,\n",
              " 'suucks': 5,\n",
              " 'witchdoctor': 1,\n",
              " 'yates': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Encode the words to integers\n",
        "# The integers start from 1 (and not 0) as we'll pad our input vectors with 0's later\n",
        "vocab_to_int = {word: idx  for idx, word in enumerate(vocabulary, 1)}\n",
        "\n",
        "\n",
        "dict(list(vocab_to_int.items())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqUAEPUhRrgk"
      },
      "source": [
        "# Encoding the Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-hCBm_uRSeSs"
      },
      "outputs": [],
      "source": [
        "reviews_int = [] # Will store encoded reviews\n",
        "\n",
        "# Encode each review\n",
        "for review in reviews_split:\n",
        "  reviews_int.append([vocab_to_int[word]  for word in review.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEEqBATa5Szf",
        "outputId": "aa33adeb-fb94-4db1-ef13-4657fc03a159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW:\n",
            "   i  m not sure why spike lee made this train wreck of a movie and conned poor stevie wonder into eternally pairing his beautiful music with this theatrical mess  i also resent the way he uses profanity as a part of the normal prose of professional blacks  the abuse of his hold on ethnic movie goers is a shame  scenes which seem to be contrived out the blue and have nothing to do with the theme or sub themes  play as if some college kid wrote this  i especially detest the ludicrous scene where the two leads are playfully sparring for no reason at all and the cops come and rough up snipes  the overacting of the leads makes one feel as if spike has no respect for his viewers or he has no clue what a movie is all about  the final scene appears to be thrown in to justify the use of a sledge hammer to tack a point in  this movie also supports the myth that all people of culture use the f  word in casual conversation  i am hoping he will realize that the rest of his movies are in the same pool as this one where he is not growing as a film maker  i think his union with scorcesee in clockers was a wise move  he should stick to making documentaries like the four little colored girls  shock movies do not an oscar make   \n",
            "\n",
            "   No. of words in the review: 240\n",
            "\n",
            "--------------------\n",
            "\n",
            "TOKENIZED VERSION:\n",
            "   [73399, 71363, 23426, 17138, 25326, 36817, 40590, 10834, 66263, 44660, 11356, 54747, 42541, 11322, 55713, 53015, 25735, 4312, 67929, 42734, 71619, 10776, 57891, 34188, 14859, 20367, 66263, 17488, 28596, 73399, 20912, 73516, 68480, 36401, 70436, 67992, 49384, 60063, 42541, 54133, 54747, 68480, 26446, 12981, 54747, 31486, 13807, 68480, 22656, 54747, 57891, 43825, 9130, 60957, 11322, 19602, 49076, 42541, 74013, 36103, 58828, 48640, 29020, 5548, 40609, 4177, 68480, 2849, 55713, 19654, 60258, 29020, 47215, 20367, 68480, 26019, 18114, 6683, 18877, 19611, 60063, 61442, 6548, 57085, 55396, 5598, 66263, 73399, 33016, 15123, 68480, 66882, 13386, 39367, 68480, 5921, 59377, 40450, 38043, 22344, 3362, 1955, 22735, 49922, 3853, 55713, 68480, 2504, 53635, 55713, 59772, 69100, 3657, 68480, 45880, 54747, 68480, 59377, 9428, 20550, 52401, 60063, 61442, 36817, 58059, 1955, 26804, 3362, 57891, 20435, 18114, 70436, 58059, 1955, 6684, 61525, 42541, 11322, 49076, 3853, 64197, 68480, 72545, 13386, 69414, 29020, 5548, 8076, 58102, 29020, 17698, 68480, 70146, 54747, 42541, 22744, 59711, 29020, 64509, 42541, 68671, 58102, 66263, 11322, 20912, 40726, 68480, 56467, 72080, 3853, 45170, 54747, 22728, 70146, 68480, 12941, 53710, 58102, 68965, 8508, 73399, 60229, 39327, 70436, 16005, 8746, 72080, 68480, 27416, 54747, 57891, 25055, 40450, 58102, 68480, 21878, 39104, 60063, 66263, 20550, 39367, 70436, 49076, 23426, 41421, 60063, 42541, 53215, 36324, 73399, 716, 57891, 64542, 20367, 46484, 58102, 32490, 25124, 42541, 55019, 2158, 70436, 6490, 60431, 29020, 55859, 45633, 60337, 68480, 21747, 49784, 3212, 36371, 29327, 25055, 47215, 23426, 10997, 45976, 9295]\n",
            "\n",
            "   No. of tokens in the encoded version: 240\n"
          ]
        }
      ],
      "source": [
        "rand_idx = random.randint(0, len(reviews_split))\n",
        "\n",
        "print(f\"REVIEW:\\n   {reviews_split[rand_idx]}\\n\")\n",
        "print(f\"   No. of words in the review: {len(reviews_split[rand_idx].split())}\\n\")\n",
        "\n",
        "print(\"-\" * 20)\n",
        "\n",
        "print(f\"\\nTOKENIZED VERSION:\\n   {reviews_int[rand_idx]}\\n\")\n",
        "print(f\"   No. of tokens in the encoded version: {len(reviews_int[rand_idx])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thGTreQR874O"
      },
      "source": [
        "# Encoding the Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3cW2g1j8_Xj",
        "outputId": "0fd1c929-4aef-440a-8ec7-f72b15c6fe41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL:\n",
            "   positive\n",
            "\n",
            "ENCODED VERSION:\n",
            "   1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rand_idx = random.randint(0, len(labels))\n",
        "\n",
        "encoded_labels = np.array([1 if label==\"positive\" else 0  for label in labels])\n",
        "\n",
        "print(f\"LABEL:\\n   {labels[rand_idx]}\")\n",
        "print(f\"\\nENCODED VERSION:\\n   {encoded_labels[rand_idx]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGfH6HUQTcGq",
        "outputId": "30b041ca-8f1e-48b1-db76-b35ea820d54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the longest review is 2514.\n",
            "The average length of reviews is 240.81\n"
          ]
        }
      ],
      "source": [
        "# Get length of the longest review\n",
        "max_len = max(len(review)  for review in reviews_int)\n",
        "\n",
        "# Get the average length of reviews\n",
        "avg_len = sum([len(review)  for review in reviews_int]) / len(reviews_int)\n",
        "\n",
        "print(f\"The length of the longest review is {max_len}.\")\n",
        "print(f\"The average length of reviews is {avg_len:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding the Reviews"
      ],
      "metadata": {
        "id": "ijWR314JggCo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9le0fC2eVgnE"
      },
      "outputs": [],
      "source": [
        "def pad_reviews_with_zeros(reviews_int, seq_length=512):\n",
        "  features = np.zeros((len(reviews_int), seq_length), dtype=np.int32)\n",
        "\n",
        "  for idx, review in enumerate(reviews_int):\n",
        "    features[idx][-len(review):] = np.array(review)[:seq_length] \n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSk7-76XI13v",
        "outputId": "e46bfbf2-40c6-4368-c56f-2d7baf994a6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ..., 47852, 30002, 16855],\n",
              "       [    0,     0,     0, ...,  5548, 72786, 60369],\n",
              "       [    0,     0,     0, ..., 29020,  1936, 60318],\n",
              "       ...,\n",
              "       [    0,     0,     0, ..., 63635, 14119, 17378],\n",
              "       [    0,     0,     0, ..., 29256, 36401, 60765],\n",
              "       [    0,     0,     0, ..., 66263, 49076,  4629]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "features = pad_reviews_with_zeros(reviews_int, seq_length=512)\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split"
      ],
      "metadata": {
        "id": "fzpw7zOYiXgw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qF01wHaz7ltV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goEMMwex7r-v",
        "outputId": "213edc2b-9b01-4acd-ce32-6d1b0cba0728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train shape: (20000, 512)\n",
            "y_train shape: (20000,)\n",
            "X_test shape : (5000, 512)\n",
            "y_test shape : (5000,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "\n",
        "print(f\"\"\"\n",
        "X_train shape: {X_train.shape}\n",
        "y_train shape: {y_train.shape}\n",
        "X_test shape : {X_test.shape}\n",
        "y_test shape : {y_test.shape}\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA8lhhlb8jvU"
      },
      "source": [
        "# Generate Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CQ44OjWj8jsG"
      },
      "outputs": [],
      "source": [
        "def get_training_dataset(X_train, y_train, batch_size=32):\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "  train_dataset = train_dataset.shuffle(buffer_size=len(X_train), reshuffle_each_iteration=True)\n",
        "  train_dataset = train_dataset.batch(batch_size)\n",
        "  train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "  return train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sc2CtwDT7llV"
      },
      "outputs": [],
      "source": [
        "def get_validation_dataset(X_test, y_test, batch_size=32):\n",
        "  validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "  validation_dataset = validation_dataset.batch(batch_size)\n",
        "\n",
        "  return validation_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RBjV7Mr4AZj4"
      },
      "outputs": [],
      "source": [
        "# Get training dataset\n",
        "train_dataset = get_training_dataset(X_train, y_train, batch_size=32)\n",
        "\n",
        "# Get validaton dataset\n",
        "validation_dataset = get_validation_dataset(X_test, y_test, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLcWk3fEAZeq",
        "outputId": "4608b685-1d77-4d29-ad01-0d7ee2f95462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t*** SAMPLE TRAIN BATCH ***\n",
            "\n",
            "Input shape: (32, 512)\n",
            "Input: \n",
            "[[    0     0     0 ...  1537 64702 22991]\n",
            " [    0     0     0 ...  7689 36878  5069]\n",
            " [68480  4294 11322 ... 27792 68480 27450]\n",
            " ...\n",
            " [    0     0     0 ... 23426 40217 11569]\n",
            " [    0     0     0 ... 42541 38160 66854]\n",
            " [    0     0     0 ...  4177 54747 17843]]\n",
            "\n",
            "\n",
            "Label shape: (32,)\n",
            "Label: \n",
            "[1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1]\n"
          ]
        }
      ],
      "source": [
        "# Get sample training dataset\n",
        "sample_x, sample_y = train_dataset.as_numpy_iterator().next()\n",
        "\n",
        "print(f\"\\t*** SAMPLE TRAIN BATCH ***\\n\")\n",
        "print(f\"Input shape: {sample_x.shape}\") \n",
        "print(f\"Input: \\n{sample_x}\")\n",
        "print(\"\\n\")\n",
        "print(f\"Label shape: {sample_y.shape}\") \n",
        "print(f\"Label: \\n{sample_y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAYFh4gbemq5"
      },
      "source": [
        "# Model Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Gfmoe1B7emq6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(vocab_size):\n",
        "  inputs = Input(shape=(512, ), dtype=tf.int32)\n",
        "  embeddings = Embedding(input_dim=len(vocab_to_int)+1, output_dim=512, input_length=512)(inputs)\n",
        "  x = LSTM(units=256, dropout=0.5, return_sequences=True)(embeddings)\n",
        "  x = LSTM(units=256, dropout=0.5)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  return Model(inputs, outputs, name=\"model\")"
      ],
      "metadata": {
        "id": "296hwNEKnnhH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model\n",
        "model = get_model(vocab_size)\n",
        "\n",
        "# Get model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP0YJlJzp6Pi",
        "outputId": "ff33be7c-1151-4a9a-99c6-8c4b41edb93f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 512, 512)          37925376  \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 512, 256)          787456    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,238,401\n",
            "Trainable params: 39,238,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the Model"
      ],
      "metadata": {
        "id": "wmj5ZJsBL4FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "FuBhN_KL4cT1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "7zv5sbfQL6tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 4\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          steps_per_epoch=len(train_dataset),\n",
        "          validation_data=validation_dataset,\n",
        "          validation_steps=len(validation_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvQ-NEVl4cQI",
        "outputId": "3d3c151d-ab60-4053-8ec6-fe2c382e72ea"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "625/625 [==============================] - 66s 100ms/step - loss: 0.5744 - accuracy: 0.6981 - val_loss: 0.5937 - val_accuracy: 0.7002\n",
            "Epoch 2/4\n",
            "625/625 [==============================] - 61s 98ms/step - loss: 0.4431 - accuracy: 0.8041 - val_loss: 0.4447 - val_accuracy: 0.8094\n",
            "Epoch 3/4\n",
            "625/625 [==============================] - 61s 98ms/step - loss: 0.2029 - accuracy: 0.9239 - val_loss: 0.3141 - val_accuracy: 0.8810\n",
            "Epoch 4/4\n",
            "625/625 [==============================] - 61s 97ms/step - loss: 0.0904 - accuracy: 0.9697 - val_loss: 0.4007 - val_accuracy: 0.8694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6edfde55d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferencing on User Generated Reviews"
      ],
      "metadata": {
        "id": "fKJlZP_9g3yb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r0iHF_p9emq-"
      },
      "outputs": [],
      "source": [
        "def predict(review, model):\n",
        "  # Convert alphabets to lowercase\n",
        "  text = review.lower()\n",
        "\n",
        "  # Remove the punctuations\n",
        "  text = ''.join([char  for char in text  if char not in punctuation])\n",
        "\n",
        "  # Encode the review\n",
        "  encoded_review = [vocab_to_int[word]  for word in text.split()]\n",
        "\n",
        "  # Pad the review\n",
        "  padded_review = pad_reviews_with_zeros([encoded_review])\n",
        "\n",
        "  # Get prediction score\n",
        "  pred = model.predict(padded_review)\n",
        "  \n",
        "\n",
        "  print(f\"Given Review:\\n   {review}\\n\")\n",
        "\n",
        "  if pred >= 0.5:\n",
        "    print(\"POSITIVE prediction detected !\")\n",
        "  else:\n",
        "    print(\"NEGATIVE prediction detected !\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test reviews\n",
        "test_review_1 = 'This movie had the best acting and the dialogue was so good. I loved it.'\n",
        "test_review_2 = \"I received the food that is one year old. No one can even smell it.\"\n",
        "test_review_3 = \"I love this sofa. Its too comfortable....\"\n",
        "test_review_4 = \"This vaccum really sucks!!!\""
      ],
      "metadata": {
        "id": "peYGjXBNuHMt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions of test reviews\n",
        "predict(test_review_1, model)\n",
        "print(\"--------\\n\\n\")\n",
        "predict(test_review_2, model)\n",
        "print(\"--------\\n\\n\")\n",
        "predict(test_review_3, model)\n",
        "print(\"--------\\n\\n\")\n",
        "predict(test_review_4, model)\n",
        "print(\"--------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOF1XArEvRO5",
        "outputId": "e8f40c37-9b63-4208-d554-afa10f3e87e0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given Review:\n",
            "   This movie had the best acting and the dialogue was so good. I loved it.\n",
            "\n",
            "POSITIVE prediction detected !\n",
            "--------\n",
            "\n",
            "\n",
            "Given Review:\n",
            "   I received the food that is one year old. No one can even smell it.\n",
            "\n",
            "NEGATIVE prediction detected !\n",
            "--------\n",
            "\n",
            "\n",
            "Given Review:\n",
            "   I love this sofa. Its too comfortable....\n",
            "\n",
            "POSITIVE prediction detected !\n",
            "--------\n",
            "\n",
            "\n",
            "Given Review:\n",
            "   This vaccum really sucks!!!\n",
            "\n",
            "NEGATIVE prediction detected !\n",
            "--------\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment_Analysis__Git.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}